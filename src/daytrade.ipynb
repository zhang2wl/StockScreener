{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BMR', 'GKIN', 'OMH', 'MRAI', 'FLES', 'DKL', 'BNZI', 'GROM', 'OCTO', 'QTI', 'UK', 'HSCS', 'NBCO', 'MCOM', 'AGRI', 'BREA', 'HOLO', 'NXU', 'VLCN', 'HQGE', 'REBN', 'LTRN', 'SPRC', 'LYT', 'OCEA', 'RVSN', 'SMX', 'ASTI', 'AULT', 'APM', 'NKGN', 'CSTF', 'CERO', 'IVP', 'MIRA', 'SIRC', 'AIMD', 'SGD', 'PBM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('smallcap.csv')  # Make sure to replace '/path/to/your/smallcap.csv' with the actual file path\n",
    "\n",
    "# Extract the tickers into a list\n",
    "tickers = df['Symbol'].tolist()\n",
    "\n",
    "# Now, 'tickers' contains all the tickers from the \"Symbol\" column of your CSV file\n",
    "print(tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily data for GKIN for the full history\n",
      "Downloading intraday data for GKIN for the past year\n",
      "No data found for month: 2023-03\n",
      "Downloading daily data for OMH for the full history\n",
      "Downloading intraday data for OMH for the past year\n",
      "Error for OMH: '2023-03-21'\n",
      "data retrival successful for OMH\n",
      "Downloading daily data for MRAI for the full history\n",
      "Downloading intraday data for MRAI for the past year\n",
      "data retrival successful for MRAI\n",
      "Downloading daily data for FLES for the full history\n",
      "Downloading intraday data for FLES for the past year\n",
      "No data found for month: 2023-03\n",
      "Downloading daily data for DKL for the full history\n",
      "Downloading intraday data for DKL for the past year\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=\u001b[39m\u001b[39m{\u001b[39;00msymbol\u001b[39m}\u001b[39;00m\u001b[39m&interval=\u001b[39m\u001b[39m{\u001b[39;00minterval\u001b[39m}\u001b[39;00m\u001b[39m&month=\u001b[39m\u001b[39m{\u001b[39;00mmonth\u001b[39m}\u001b[39;00m\u001b[39m&outputsize=\u001b[39m\u001b[39m{\u001b[39;00moutputsize\u001b[39m}\u001b[39;00m\u001b[39m&apikey=\u001b[39m\u001b[39m{\u001b[39;00mapi_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     data \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()  \u001b[39m# Data is in JSON format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m# The exact key for the time series data depends on the interval and function used\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wenlongzhang/Documents/ML/stock/src/daytrade.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# Adjust the key based on the actual structure of your JSON response\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Documents/ML/stock/tf-env/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Alpha Vantage API key\n",
    "api_key = 'HGLDEL3XDK78QXPN'\n",
    "symbol = 'IBM'  # Example symbol\n",
    "interval = '5min'  # Data interval\n",
    "outputsize = 'full'  # Get the full intraday data for a specific month\n",
    "ts = TimeSeries(key=api_key, output_format='pandas')\n",
    "\n",
    "tickers = [ 'GKIN', 'OMH', 'MRAI', 'FLES', 'DKL', 'BNZI', 'GROM', 'OCTO', 'QTI', 'UK', 'HSCS', 'NBCO', 'MCOM', 'AGRI', 'BREA', 'HOLO', 'NXU', 'VLCN', 'HQGE', 'REBN', 'LTRN', 'SPRC', 'LYT', 'OCEA', 'RVSN', 'SMX', 'ASTI', 'AULT', 'APM', 'NKGN', 'CSTF', 'CERO', 'IVP', 'MIRA', 'SIRC', 'AIMD', 'SGD', 'PBM']\n",
    "\n",
    "# Function to generate the past 12 months in 'YYYY-MM' format\n",
    "def generate_past_12_months():\n",
    "    return [(datetime.now() - timedelta(days=30*i)).strftime('%Y-%m') for i in range(0, 13)]\n",
    "\n",
    "# Generate the list of the past 12 months\n",
    "months = generate_past_12_months()\n",
    "\n",
    "success_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "\n",
    "    # Initialize a DataFrame to store all the data\n",
    "    all_data_df = pd.DataFrame()\n",
    "    results = []\n",
    "    symbol=ticker\n",
    "\n",
    "    print(f\"Downloading daily data for {ticker} for the full history\")\n",
    "    try:\n",
    "        # Get daily data\n",
    "        daily_data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "        daily_data.sort_index(ascending=True, inplace=True)\n",
    "        daily_data.index = pd.to_datetime(daily_data.index)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {ticker}: {e}\")\n",
    "\n",
    "    print(f\"Downloading intraday data for {ticker} for the past year\")\n",
    "\n",
    "    # Calculate the slices for the past 12 months from the current date\n",
    "    for month in months[::-1]:\n",
    "        try:\n",
    "            url = f'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol={symbol}&interval={interval}&month={month}&outputsize={outputsize}&apikey={api_key}'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()  # Data is in JSON format\n",
    "\n",
    "            # The exact key for the time series data depends on the interval and function used\n",
    "            # Adjust the key based on the actual structure of your JSON response\n",
    "            time_series_key = f\"Time Series ({interval})\"\n",
    "\n",
    "            if time_series_key in data:\n",
    "                time_series_data = data[\"Time Series (5min)\"]\n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame.from_dict(time_series_data, orient='index')\n",
    "                df.index = pd.to_datetime(df.index)  # Converting index to datetime\n",
    "                df.sort_index(inplace=True)  # Sorting by datetime index\n",
    "\n",
    "                # Concatenate with the main DataFrame\n",
    "                all_data_df = pd.concat([all_data_df, df])\n",
    "\n",
    "            else:\n",
    "                print(f\"No data found for month: {month}\")\n",
    "                break\n",
    "\n",
    "            for day in pd.unique(df.index.date):\n",
    "                day_str = day.strftime('%Y-%m-%d')\n",
    "                day_data = all_data_df.between_time('09:30', '10:30').loc[day_str]\n",
    "                if not day_data.empty:\n",
    "                    open_price  = float(day_data.iloc[0]['1. open'])\n",
    "                    close_price = float(day_data.iloc[-1]['4. close'])\n",
    "                    high_price  = float(day_data['2. high'].max())\n",
    "                    low_price   = float(day_data['3. low'].min())\n",
    "\n",
    "                    # Find the last trading day's close price\n",
    "                    today_open = daily_data.loc[day_str,'1. open']\n",
    "                    previous_days_data = daily_data[daily_data.index < day_str]\n",
    "\n",
    "                    # Calculate the gap percentage compared to yesterday's close\n",
    "                    if not previous_days_data.empty:\n",
    "                        previous_day_close = previous_days_data.iloc[-1]['4. close']\n",
    "                        previous_day_open = previous_days_data.iloc[-1]['1. open']\n",
    "                        previous_day_high = previous_days_data.iloc[-1]['2. high']\n",
    "                        previous_day_low  = previous_days_data.iloc[-1]['3. low']\n",
    "                        previous_day_volume  = previous_days_data.iloc[-1]['5. volume']\n",
    "\n",
    "                        two_days_ago_close = previous_days_data.iloc[-2]['4. close']\n",
    "                        two_days_ago_open = previous_days_data.iloc[-2]['1. open']\n",
    "                        two_days_ago_high = previous_days_data.iloc[-2]['2. high']\n",
    "                        two_days_ago_low  = previous_days_data.iloc[-2]['3. low']\n",
    "                        two_days_ago_volume = previous_days_data.iloc[-2]['5. volume']\n",
    "\n",
    "                        # print(type(previous_day_close), type(open_price))\n",
    "                        gap_percentage = ((today_open - previous_day_close) / previous_day_close) * 100\n",
    "                    else:\n",
    "                        gap_percentage = None\n",
    "\n",
    "                    results.append([day, ticker, open_price, close_price, high_price, low_price, gap_percentage, previous_day_close, previous_day_open, previous_day_high, previous_day_low, previous_day_volume, two_days_ago_close, two_days_ago_open, two_days_ago_high, two_days_ago_low, two_days_ago_volume])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {ticker}: {e}\")\n",
    "\n",
    "    # # # Convert the results into a DataFrame with an additional column for the gap percentage\n",
    "    results_df = pd.DataFrame(results, columns=['Date', 'Ticker', '9:30 Price', '10:30 Price', 'High Price', 'Low Price', 'Gap Percentage', 'previous_day_close',  'previous_day_open', 'previous_day_high', 'previous_day_low', 'previous_day_volume', 'two_days_ago_close', 'two_days_ago_open', 'two_days_ago_high', 'two_days_ago_low', 'two_days_ago_volume'])\n",
    "\n",
    "    results_df.to_csv(f'{ticker}.csv', index=False)\n",
    "    if not results_df.empty:\n",
    "        success_list.append(ticker)\n",
    "        print(f'---> Data retrival successful for {ticker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1. open  2. high   3. low  4. close  5. volume\n",
      "date                                                      \n",
      "1999-11-01    1.125    1.125   1.1250    1.1250        0.0\n",
      "1999-11-02    1.125    1.125   1.1250    1.1250        0.0\n",
      "1999-11-03    1.125    1.125   1.1250    1.1250        0.0\n",
      "1999-11-04    1.125    1.125   1.0625    1.0625        0.0\n",
      "1999-11-05    1.125    1.125   1.0625    1.0625      100.0\n",
      "...             ...      ...      ...       ...        ...\n",
      "2024-03-04   34.500   34.500  32.0200   32.0200      604.0\n",
      "2024-03-05   32.020   32.020  32.0200   32.0200        0.0\n",
      "2024-03-06   32.020   32.020  32.0200   32.0200        0.0\n",
      "2024-03-07   32.020   32.020  32.0200   32.0200        0.0\n",
      "2024-03-08   32.020   32.020  32.0200   32.0200        0.0\n",
      "\n",
      "[6108 rows x 5 columns]\n",
      "                     1. open  2. high   3. low 4. close 5. volume\n",
      "2023-05-01 09:30:00  10.6400  11.1100  10.6100  10.9960      3700\n",
      "2023-05-01 13:20:00  10.6800  10.7200  10.6800  10.7200      5295\n",
      "2023-05-01 13:25:00  10.7200  10.7200  10.6950  10.6950       600\n",
      "2023-05-01 13:30:00  10.7100  10.7100  10.7100  10.7100      1000\n",
      "2023-05-01 13:50:00  10.6950  10.6950  10.6800  10.6850       781\n",
      "...                      ...      ...      ...      ...       ...\n",
      "2023-05-30 15:55:00  10.7400  10.7400  10.7400  10.7400       100\n",
      "2023-05-30 16:00:00  10.7400  10.8500  10.7400  10.8500       104\n",
      "2023-05-31 09:30:00  10.7400  10.7400  10.7400  10.7400      1300\n",
      "2023-05-31 14:30:00  10.7500  10.7500  10.7500  10.7500       100\n",
      "2023-05-31 16:00:00  10.7500  10.7500  10.7500  10.7500       100\n",
      "\n",
      "[79 rows x 5 columns]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Date, Ticker, 9:30 Price, 10:30 Price, High Price, Low Price, Gap Percentage, previous_day_close, previous_day_open, previous_day_high, previous_day_low, two_days_ago_close, two_days_ago_open, two_days_ago_high, two_days_ago_low]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# print(results_df.head())\n",
    "# # results_df.to_csv(f'{ticker}.csv', index=False)\n",
    "\n",
    "print(daily_data)\n",
    "# # daily_data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "# # daily_data.sort_index(ascending=True, inplace=True)\n",
    "# # daily_data.index = pd.to_datetime(daily_data.index)\n",
    "# # daily_data.to_csv('daily_data.csv', index=True)\n",
    "\n",
    "# print(months)\n",
    "# # previous_days_data = daily_data[daily_data.index < '2023-03-02']\n",
    "# print(previous_days_data)\n",
    "# print(daily_data.head())\n",
    "\n",
    "# previous_day_close = previous_days_data.iloc[-1]['4. close']\n",
    "# open_price  = float(daily_data.loc['2023-03-02', '1. open'])\n",
    "# print(previous_day_close,open_price)\n",
    "\n",
    "# for day in pd.unique(all_data_df.index.date):\n",
    "#     day_str = day.strftime('%Y-%m-%d')\n",
    "\n",
    "print(df)\n",
    "print(all_data_df)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      1. open   2. high    3. low  4. close 5. volume\n",
      "2024-03-01 04:15:00  185.4600  185.4600  185.4600  185.4600         2\n",
      "2024-03-01 04:25:00  185.4700  185.4700  185.4600  185.4600         2\n",
      "2024-03-01 04:30:00  185.0600  185.4600  185.0600  185.4600         2\n",
      "2024-03-01 04:35:00  185.4500  185.4500  185.4500  185.4500         1\n",
      "2024-03-01 04:45:00  185.0900  185.0900  185.0900  185.0900        71\n",
      "...                       ...       ...       ...       ...       ...\n",
      "2024-03-08 19:35:00  196.2300  196.2300  196.2300  196.2300         2\n",
      "2024-03-08 19:40:00  195.4900  195.9400  195.4900  195.9400         8\n",
      "2024-03-08 19:45:00  195.9500  195.9500  195.4900  195.5000        32\n",
      "2024-03-08 19:50:00  195.5000  195.5000  195.5000  195.5000         3\n",
      "2024-03-08 19:55:00  195.4900  195.4900  195.4800  195.4800       105\n",
      "\n",
      "[1072 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
